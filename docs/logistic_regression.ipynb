{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Intro\n",
        "\n",
        "In this notebook, we learn how to run a (binomial) logistic regression using R. The example in this notebook is taken from the lab section in chapter 4 of the textbook [An Introduction to Statistical Learning with Applicaiton in R (ISLR2)](https://www.statlearning.com/) (with minor modifications). You can find the original full notebook (in html) [here](https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch4-classification-lab.html)."
      ],
      "metadata": {
        "id": "BIX_bdf1IqCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set a random seed so results are reproducible\n",
        "set.seed(123)"
      ],
      "metadata": {
        "id": "XIQPcn7V8_EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Import and inspect the data"
      ],
      "metadata": {
        "id": "diJQo-_pJfce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a stock market dataset. See the data description below.\n",
        "\n",
        "**S&P Stock Market Data**\n",
        "\n",
        "*Description*\n",
        "\n",
        "Daily percentage returns for the S&P 500 stock index between 2001 and 2005.\n",
        "\n",
        "*Variables*\n",
        "\n",
        "1. Year: The year that the observation was recorded\n",
        "2. Lag1: Percentage return for previous day\n",
        "3. Lag2: Percentage return for 2 days previous\n",
        "4. Lag3: Percentage return for 3 days previous\n",
        "5. Lag4: Percentage return for 4 days previous\n",
        "6. Lag5: Percentage return for 5 days previous\n",
        "7. Volume: Volume of shares traded (number of daily shares traded in billions)\n",
        "8. Today: Percentage return for today\n",
        "9. Direction: \"Down\" or \"Up\" indicating whether the market had a positive or negative return on a given day\n",
        "\n",
        "*Source*\n",
        "\n",
        "Raw values of the S&P 500 were obtained from Yahoo Finance and then converted to percentages and lagged.\n",
        "\n",
        "*References*\n",
        "\n",
        "James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning with applications in R, https://www.statlearning.com, Springer-Verlag, New York"
      ],
      "metadata": {
        "id": "MrzSqztPJ719"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the smarket data (using base R read.csv())\n",
        "data_url <- \"https://github.com/tdmdal/datasets-teaching/raw/main/smarket/smarket.csv\"\n",
        "smarket <- read.csv(data_url)"
      ],
      "metadata": {
        "id": "EUo4ANfZMjGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a few beginning rows of the data\n",
        "head(smarket)"
      ],
      "metadata": {
        "id": "FQ1_9QhwM7f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset doesn't have a date column (only year is given), but a careful look at the lag variables reveals that the dataset appears to be ordered by date. Let's give it a quick check."
      ],
      "metadata": {
        "id": "cb6Mj3lr4EeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the dataset is ordered by date\n",
        "# all() checks if all elements are true, https://stat.ethz.ch/R-manual/R-devel/library/base/html/all.html\n",
        "# head(smarket$Lag1, -1) returns a vector with all values of Lag1 column except the last one\n",
        "# smarket$Lag2[-1] returns a vector with all values of Lag2 column except the first one\n",
        "all(head(smarket$Lag1, -1) == smarket$Lag2[-1])"
      ],
      "metadata": {
        "id": "TI6Jbbi75abQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the structure of the data\n",
        "str(smarket)"
      ],
      "metadata": {
        "id": "aWy5lhvyM9PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary statistics\n",
        "summary(smarket)"
      ],
      "metadata": {
        "id": "g5YWeRznPV3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform a correlation analysis for the first 8 variables/columns."
      ],
      "metadata": {
        "id": "I5M-WTcYz_z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation analysis\n",
        "# [, -9] means all rows, and all columns except the 9th one\n",
        "cor(smarket[, -9])"
      ],
      "metadata": {
        "id": "uzgSRvaNOikv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the correlations between the lag variables and today's returns are close to zero. `Volume` is positively correlated with `Year`, which indicates that the trading volume is increasing over time. We can also see the positive trend over time in the below plots."
      ],
      "metadata": {
        "id": "BDEMchh9K_y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot volumn against year (no date info in the dataset)\n",
        "plot(smarket$Year, smarket$Volume)"
      ],
      "metadata": {
        "id": "uo7uzEDAPfpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since the data is ordered by date, plot volumn against row index too\n",
        "plot(smarket$Volume)"
      ],
      "metadata": {
        "id": "GLkZWSmf9ps2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Logistic regression"
      ],
      "metadata": {
        "id": "g9qnDhWXMQ-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Prepare the data"
      ],
      "metadata": {
        "id": "Wut3jvDvPD25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Category variable as `factor` type\n",
        "\n",
        "We will run a logistic regression to predict whether the market is going up or down on a giving data using lag returns.\n",
        "\n",
        "First, we will turn the `Direction` column from its current `character` type to the `factor` type so that R knows that `Direction` is a categorical variable, and takes that into account when running the logistic regression."
      ],
      "metadata": {
        "id": "JEtIEGfrAt0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the Direction column from chr to factor/categorical type\n",
        "smarket$Direction = as.factor(smarket$Direction)\n",
        "str(smarket)"
      ],
      "metadata": {
        "id": "baLhMOYMderP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the `Direction` column has been converted from `chr` type to `factor` type.\n",
        "\n",
        "The category \"Down\" is displayed first (after the \"w/ 2 levels\"), and this tells us that \"Down\" is the reference category. (You can also use `levels(smarket$Direction)` to double check it as shown below.)"
      ],
      "metadata": {
        "id": "83V2lFbclAtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check which category is the reference category\n",
        "print(levels(smarket$Direction))"
      ],
      "metadata": {
        "id": "M_44x0Isi0sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since \"\"Down\" is the reference category, if we run a logistic regression model of `Direction` against all the lag variables, we will be predicting the probability of \"Up\". In other words, we are modeling the log odds of \"Up\" vs \"Down\", $log(\\frac{prob(Up)}{prob(Down)})$, as a linear function of all the lag variables, and \"Down\" is a reference category.\n",
        "\n",
        "If instead you want to predict the probability of being \"Down\", you can change the reference category to \"Up\" using the `relevel()` function, `smarket$Direction <- relevel(smarket$Direction, ref = \"Up\")`."
      ],
      "metadata": {
        "id": "9-69xBfNAIAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Training & test data split\n",
        "\n",
        "Next, let us split the data into training and test set. We will train/estimate the model using the training set, and evaluate the (trained/estimated) model on the *held-out* test set. We do this to prevent overfitting our model. Overfitting is the problem that an estimated model performs well on the training set but fails to generalize its performance in real world prediction. The *held-out* (never-seen-by-model) test set can be seen as simulated real world data. Evaluating the model on test set allows us to obtain an unbiased estimate on how well the model may perform in the real world, and catch any potential overfitting issue.\n",
        "\n",
        "We will use the 2005 data for testing and the rest for training. Note that in this particular setting, you should not *randomly* split the data into training and test set. For the model to be useful for prediction, it must be trained on past data and tested on future data."
      ],
      "metadata": {
        "id": "yNnIwEMNQ032"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pick up all data that are from 2005\n",
        "# train_idx is a boolean vector of TRUE or FALSE\n",
        "train_idx <- (smarket$Year < 2005)\n",
        "\n",
        "# obtain training and test dataframes\n",
        "smarket_train <- smarket[train_idx, ]\n",
        "smarket_test <- smarket[!train_idx, ]\n",
        "\n",
        "# check the sizes of training and test data\n",
        "print(dim(smarket_train))\n",
        "print(dim(smarket_test))"
      ],
      "metadata": {
        "id": "jcjJhK8QTOXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Run logistic regressions\n",
        "\n",
        "Now we are ready for our logistic regression analysis.\n",
        "\n",
        "We will use the `glm()` function (generalized linear model) to run a logistic regression. We must pass the `family = binomial` parameter to the `glm()` function to indicate that we want to run a logistic regression but not other generalized linear model.\n",
        "\n",
        "In addition, we will only use the training data for the estimation so we will specify the `data` parameter as `data = smarket_train`.\n",
        "\n",
        "After running the analysis, similar as in linear regression analysis, we will use the `summary()` function to print out a report."
      ],
      "metadata": {
        "id": "vQk6tnIwGa9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run a logistic regression on training set\n",
        "logistic_fit <- glm(\n",
        "    formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5,\n",
        "    data = smarket_train, family = binomial\n",
        "  )\n",
        "\n",
        "# display logistic regression result\n",
        "summary(logistic_fit)"
      ],
      "metadata": {
        "id": "DB7qU3SgQCPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other than the above logistic regression report, you can use the `coef()` function to access the coefficients estimated, or use the `summary()` (together with the `$` operator) to access particular aspects of the fitted model."
      ],
      "metadata": {
        "id": "DqJLpP5KeWLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display the coefficients estimated\n",
        "print(coef(logistic_fit))"
      ],
      "metadata": {
        "id": "e55vM242e-Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the coefficients estimated and related statistics using summary\n",
        "print(summary(logistic_fit)$coef)"
      ],
      "metadata": {
        "id": "q6v76OdNgmiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The obtained coefficients all have large p-values (>0.05), indicating that the coefficients are not statistically different from zeros. Nevertheless, we aim to build a predictive model, so we care less about the statistical inference of the model. We will instead use the test data to evaluate the model performance. Before that, let us check the model performance on training dataset."
      ],
      "metadata": {
        "id": "hCjch-KagcZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the prob of Up on the training set\n",
        "prob_train <- predict(logistic_fit, type = \"response\")\n",
        "print(prob_train[1:10])"
      ],
      "metadata": {
        "id": "czk2LR62hLQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used `predict()` function to predict the probability that the market will go up (recall that our reference category is \"Down\"), given values of the predictors. The `type = \"response\"` option tells the  `predict()` function to output probabilities of the form $P(Y=Up)$, as opposed to other information such as the logits (i.e. the log odds of \"Up\" vs \"Down\"). We didn't supply any data to the `predict()` function, so by default the training data was used for the prediction.\n",
        "\n",
        "In order to calculate prediction accuracy and other interested metrics, we must convert these probability to concrete predictions, \"Up\" or \"Down\". Let us set the threshold probability to be 0.5, i.e., if the probability is above 0.5, then predict \"Up\", and otherwise predict \"Down\". Note that this cut-off probability is a hyper-parameter that you can adjust depending on what metric you want to optimize."
      ],
      "metadata": {
        "id": "1jxmAiLq4ee8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a character vector of the length of training data, and set all its elements to \"Down\"\n",
        "pred_train <- rep(\"Down\", nrow(smarket_train))\n",
        "\n",
        "# set those elements with prob of Up more than 0.5 to \"Up\"\n",
        "pred_train[prob_train > 0.5] = \"Up\""
      ],
      "metadata": {
        "id": "7hgiYyTc4tS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can produce a table of predicted market movement against actual market movement. This table is often called *confusion matrix*."
      ],
      "metadata": {
        "id": "qR1MiVos8RLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# produce a confusion matrix for the prediction on training set\n",
        "actual_train <- smarket_train$Direction\n",
        "table(pred_train, actual_train)"
      ],
      "metadata": {
        "id": "0swvdYHD8f-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the accuracy rate on training set\n",
        "mean(pred_train == smarket_train$Direction)"
      ],
      "metadata": {
        "id": "9w1azvq_8zcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the error rate on training set\n",
        "# != means not equal\n",
        "mean(pred_train != smarket_train$Direction)"
      ],
      "metadata": {
        "id": "gDOBLXo2CvBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the training set, the accuracy rate is barely better than a random guess (which would get 50% correct on average). Let us find the accuracy rate on the test set. This time, when calling the `predict()` function, we will specify the option `newdata = smarket_test`."
      ],
      "metadata": {
        "id": "Xc757LXrBFfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the prob of Up on the test set\n",
        "prob_test <- predict(logistic_fit, newdata = smarket_test, type = \"response\")\n",
        "print(prob_test[1:10])"
      ],
      "metadata": {
        "id": "BB3d-L0U-oQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a character vector of the length of test data, and set all its elements to \"Down\"\n",
        "pred_test <- rep(\"Down\", nrow(smarket_test))\n",
        "\n",
        "# set those elements with prob of Up more than 0.5 to \"Up\"\n",
        "pred_test[prob_test > 0.5] = \"Up\""
      ],
      "metadata": {
        "id": "CfZgdrHwBreT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# produce a confusion matrix for the prediction on test set\n",
        "actual_test <- smarket_test$Direction\n",
        "table(pred_test, actual_test)"
      ],
      "metadata": {
        "id": "_z21xPS8B183"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the accuracy rate on test set\n",
        "mean(pred_test == smarket_test$Direction)"
      ],
      "metadata": {
        "id": "vTUt0cYdCKgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the error rate on test set\n",
        "# != means not equal\n",
        "mean(pred_test != smarket_test$Direction)"
      ],
      "metadata": {
        "id": "Q8mgKxGcCnkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model seems to do slightly better on the test set. It's better than a random guess (50% accuracy for random guess predictions). However, what if we adopt a naive strategy that simply always predict \"Up\"."
      ],
      "metadata": {
        "id": "mcB86QlmCS4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the accuracy rate on test set if we always predict Up\n",
        "# this is equivalent to calculating the proportion of \"Up\" in the test set\n",
        "sum(smarket_test$Direction == \"Up\") / nrow(smarket_test)"
      ],
      "metadata": {
        "id": "bltrrOTiDKLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we always predict \"Up\", we will get 56% accuracy, not far from the 58.7% obtained by the model. The current model doesn't seem to be too useful."
      ],
      "metadata": {
        "id": "zQHFT4UgEXSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise\n",
        "\n",
        "The data appears to be ordered by date. Create a few lag trading volume variables, for example, past 1-day and 2-day volumes. Perform a similar logistic regression analysis as above but this time add those lag volume variables you created as predictors too. Do you see the test accuracy improve?"
      ],
      "metadata": {
        "id": "1tG4fSpxGjPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "PNHLvkhkEdL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}